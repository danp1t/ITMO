{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d92302b7-7364-4528-b532-8302080dac0c",
   "metadata": {},
   "source": [
    "# Путинцев Данил P3307 Вариант четный. Метод k-ближайших соседей. Лабораторная работа №4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea10e5ae-33f6-456f-ae56-f04bff2a93d9",
   "metadata": {},
   "source": [
    "Деревья решений — алгоритм машинного обучения, строящий иерархическую структуру решающих правил. Алгоритм C4.5 использует нормированный прирост информации (Gain Ratio) для выбора оптимальных признаков. В данной реализации добавлен случайный отбор √n признаков в каждом узле для повышения устойчивости модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe931559-540e-4579-a9ef-6d31f7d57f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "\n",
    "class Node:\n",
    "    \"\"\"Узел дерева решений\"\"\"\n",
    "    def __init__(self, feature=None, value=None, results=None, children=None):\n",
    "        self.feature = feature      # Индекс признака для разделения\n",
    "        self.value = value          # Значение признака\n",
    "        self.results = results      # Распределение классов (для листьев)\n",
    "        self.children = children    # Список дочерних узлов\n",
    "\n",
    "class DecisionTree:\n",
    "    \"\"\"Класс дерева решений с случайным выбором признаков\"\"\"\n",
    "    \n",
    "    def __init__(self, max_depth=10, min_samples_split=2):\n",
    "        \"\"\"\n",
    "        Инициализация дерева решений\n",
    "        \n",
    "        Parameters:\n",
    "        max_depth - максимальная глубина дерева\n",
    "        min_samples_split - минимальное количество samples для разделения\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.root = None\n",
    "        self.feature_names = None\n",
    "\n",
    "    def fit(self, X, y, feature_names=None):\n",
    "        \"\"\"\n",
    "        Построение дерева решений на обучающих данных\n",
    "        \n",
    "        Parameters:\n",
    "        X - матрица признаков\n",
    "        y - вектор меток классов\n",
    "        feature_names - названия признаков\n",
    "        \"\"\"\n",
    "        self.feature_names = feature_names\n",
    "        self.root = self._build_tree(X, y, depth=0)\n",
    "\n",
    "    def _build_tree(self, X, y, depth):\n",
    "        \"\"\"\n",
    "        Рекурсивное построение дерева решений\n",
    "        \n",
    "        Parameters:\n",
    "        X - матрица признаков\n",
    "        y - вектор меток классов\n",
    "        depth - текущая глубина дерева\n",
    "        \n",
    "        Returns:\n",
    "        Node - узел дерева\n",
    "        \"\"\"\n",
    "        # Вычисляем распределение классов для текущего узла\n",
    "        node_distribution = self._calculate_class_distribution(y)\n",
    "        \n",
    "        # Условия остановки рекурсии\n",
    "        if len(y) < self.min_samples_split or depth >= self.max_depth:\n",
    "            return Node(results=node_distribution)\n",
    "        \n",
    "        # Если все элементы одного класса\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return Node(results=node_distribution)\n",
    "\n",
    "        # Случайный выбор √n признаков\n",
    "        n_features = X.shape[1]\n",
    "        selected_features = np.random.choice(\n",
    "            n_features, \n",
    "            size=max(1, int(math.sqrt(n_features))), \n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        # Поиск лучшего признака для разделения\n",
    "        best_gain = 0\n",
    "        best_feature = None\n",
    "        best_splits = None\n",
    "\n",
    "        for feature in selected_features:\n",
    "            gain, splits = self._best_split(X, y, feature)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_feature = feature\n",
    "                best_splits = splits\n",
    "\n",
    "        # Если не удалось найти хорошее разделение\n",
    "        if best_gain == 0:\n",
    "            return Node(results=node_distribution)\n",
    "\n",
    "        # Рекурсивное построение дочерних узлов\n",
    "        children = []\n",
    "        for value, (X_sub, y_sub) in best_splits.items():\n",
    "            if len(y_sub) == 0:\n",
    "                continue\n",
    "            child = self._build_tree(X_sub, y_sub, depth + 1)\n",
    "            children.append((value, child))\n",
    "        \n",
    "        # Если не создано ни одного дочернего узла, возвращаем лист\n",
    "        if not children:\n",
    "            return Node(results=node_distribution)\n",
    "        \n",
    "        # Создаем внутренний узел с распределением\n",
    "        node = Node(feature=best_feature, children=children)\n",
    "        node.results = node_distribution  # Сохраняем распределение для надежности\n",
    "        return node\n",
    "\n",
    "    def _best_split(self, X, y, feature):\n",
    "        \"\"\"\n",
    "        Нахождение лучшего разделения для заданного признака\n",
    "        \n",
    "        Parameters:\n",
    "        X - матрица признаков\n",
    "        y - вектор меток классов\n",
    "        feature - индекс признака для анализа\n",
    "        \n",
    "        Returns:\n",
    "        gain_ratio - значение Gain Ratio\n",
    "        splits - словарь с разделенными данными\n",
    "        \"\"\"\n",
    "        values = np.unique(X[:, feature])\n",
    "        if len(values) < 2:\n",
    "            return 0, {}\n",
    "        \n",
    "        # Расчет энтропии до разделения\n",
    "        base_entropy = self._calculate_entropy(y)\n",
    "        \n",
    "        # Создание разделений\n",
    "        splits = {}\n",
    "        for value in values:\n",
    "            mask = X[:, feature] == value\n",
    "            splits[value] = (X[mask], y[mask])\n",
    "\n",
    "        # Расчет прироста информации и информации разделения\n",
    "        info_gain = base_entropy\n",
    "        split_info = 0\n",
    "        \n",
    "        for (X_sub, y_sub) in splits.values():\n",
    "            p = len(y_sub) / len(y)\n",
    "            info_gain -= p * self._calculate_entropy(y_sub)\n",
    "            if p > 0:\n",
    "                split_info -= p * math.log2(p)\n",
    "\n",
    "        # Gain Ratio\n",
    "        if split_info == 0:\n",
    "            return 0, {}\n",
    "            \n",
    "        gain_ratio = info_gain / split_info\n",
    "        return gain_ratio, splits\n",
    "\n",
    "    def _calculate_entropy(self, y):\n",
    "        \"\"\"\n",
    "        Расчет энтропии множества меток\n",
    "        \n",
    "        Parameters:\n",
    "        y - вектор меток классов\n",
    "        \n",
    "        Returns:\n",
    "        entropy - значение энтропии\n",
    "        \"\"\"\n",
    "        if len(y) == 0:\n",
    "            return 0\n",
    "        counts = np.bincount(y)\n",
    "        probabilities = counts / len(y)\n",
    "        entropy = 0\n",
    "        for p in probabilities:\n",
    "            if p > 0:\n",
    "                entropy -= p * math.log2(p)\n",
    "        return entropy\n",
    "\n",
    "    def _calculate_class_distribution(self, y):\n",
    "        \"\"\"\n",
    "        Расчет распределения классов в множестве\n",
    "        \n",
    "        Parameters:\n",
    "        y - вектор меток классов\n",
    "        \n",
    "        Returns:\n",
    "        distribution - словарь с распределением классов\n",
    "        \"\"\"\n",
    "        class_counts = {}\n",
    "        for cls in y:\n",
    "            class_counts[cls] = class_counts.get(cls, 0) + 1\n",
    "        \n",
    "        total = len(y)\n",
    "        return {cls: count / total for cls, count in class_counts.items()}\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Предсказание вероятностей классов\n",
    "        \n",
    "        Parameters:\n",
    "        X - матрица признаков\n",
    "        \n",
    "        Returns:\n",
    "        probas - вектор вероятностей положительного класса\n",
    "        \"\"\"\n",
    "        return np.array([self._predict_single(x) for x in X])\n",
    "\n",
    "    def _predict_single(self, x):\n",
    "        \"\"\"\n",
    "        Предсказание для одного примера\n",
    "        \n",
    "        Parameters:\n",
    "        x - вектор признаков одного примера\n",
    "        \n",
    "        Returns:\n",
    "        probability - вероятность положительного класса\n",
    "        \"\"\"\n",
    "        node = self.root\n",
    "        while node is not None and node.children is not None:\n",
    "            value = x[node.feature]\n",
    "            found_child = False\n",
    "            for child_value, child_node in node.children:\n",
    "                if child_value == value:\n",
    "                    node = child_node\n",
    "                    found_child = True\n",
    "                    break\n",
    "            if not found_child:\n",
    "                break\n",
    "        \n",
    "        # Безопасное получение вероятности\n",
    "        if node is not None and node.results is not None:\n",
    "            return node.results.get(1, 0.0)\n",
    "        else:\n",
    "            return 0.0  # Возвращаем 0 если что-то пошло не так\n",
    "\n",
    "    def predict(self, X, threshold=0.5):\n",
    "        \"\"\"\n",
    "        Предсказание классов\n",
    "        \n",
    "        Parameters:\n",
    "        X - матрица признаков\n",
    "        threshold - порог для бинаризации вероятностей\n",
    "        \n",
    "        Returns:\n",
    "        predictions - вектор предсказанных классов\n",
    "        \"\"\"\n",
    "        probas = self.predict_proba(X)\n",
    "        return (probas >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de480de4-e246-4f46-868c-82982bc0fb5b",
   "metadata": {},
   "source": [
    "## Загрузка и предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7183fe2d-6dce-442e-a137-b5c44c8968b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные: 8124 образцов, 22 признаков\n",
      "Распределение классов: 4208 положительных, 3916 отрицательных\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "def load_data_from_csv(filename):\n",
    "    \"\"\"\n",
    "    Загрузка данных из CSV файла с использованием модуля csv\n",
    "    \n",
    "    Parameters:\n",
    "    filename - путь к CSV файлу\n",
    "    \n",
    "    Returns:\n",
    "    X - матрица признаков\n",
    "    y - вектор меток классов\n",
    "    feature_names - список названий признаков\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    with open(filename, 'r', newline='', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f)\n",
    "        header = next(reader)  # Чтение заголовка\n",
    "        feature_names = header[1:]\n",
    "        \n",
    "        for row in reader:\n",
    "            if row:  # Пропуск пустых строк\n",
    "                label = 1 if row[0] == 'e' else 0\n",
    "                features = row[1:]\n",
    "                labels.append(label)\n",
    "                data.append(features)\n",
    "    \n",
    "    return np.array(data), np.array(labels), feature_names\n",
    "\n",
    "def encode_features(X):\n",
    "    \"\"\"\n",
    "    Кодирование категориальных признаков в числовые\n",
    "    \n",
    "    Parameters:\n",
    "    X - матрица категориальных признаков\n",
    "    \n",
    "    Returns:\n",
    "    encoded_X - матрица закодированных признаков\n",
    "    feature_encodings - список словарей кодирования для каждого признака\n",
    "    \"\"\"\n",
    "    encoded_X = np.zeros(X.shape, dtype=int)\n",
    "    feature_encodings = []\n",
    "    \n",
    "    for i in range(X.shape[1]):\n",
    "        unique_values = np.unique(X[:, i])\n",
    "        encoding = {val: idx for idx, val in enumerate(unique_values)}\n",
    "        feature_encodings.append(encoding)\n",
    "        for j in range(X.shape[0]):\n",
    "            encoded_X[j, i] = encoding[X[j, i]]\n",
    "    \n",
    "    return encoded_X, feature_encodings\n",
    "\n",
    "# Загрузка данных\n",
    "X, y, feature_names = load_data_from_csv('/home/danil/github_repos/ITMO/course3/AI/lab5/test.csv')\n",
    "X_encoded, feature_encodings = encode_features(X)\n",
    "\n",
    "print(f\"Данные: {X.shape[0]} образцов, {X.shape[1]} признаков\")\n",
    "print(f\"Распределение классов: {np.sum(y)} положительных, {len(y) - np.sum(y)} отрицательных\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14e416f-f5ed-49b3-b031-ba5fe97d80d5",
   "metadata": {},
   "source": [
    "## Разделение данных и обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "648fa8c3-f35d-4286-95f9-58e22d664a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обучающая выборка: 5686 образцов\n",
      "Тестовая выборка: 2438 образцов\n",
      "Модель успешно обучена\n"
     ]
    }
   ],
   "source": [
    "split_idx = int(0.7 * len(X))\n",
    "X_train, X_test = X_encoded[:split_idx], X_encoded[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"Обучающая выборка: {X_train.shape[0]} образцов\")\n",
    "print(f\"Тестовая выборка: {X_test.shape[0]} образцов\")\n",
    "\n",
    "# Обучение модели\n",
    "tree = DecisionTree(max_depth=4, min_samples_split=2)\n",
    "tree.fit(X_train, y_train, feature_names=feature_names)\n",
    "print(\"Модель успешно обучена\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de935db4-f5ae-4530-a223-372a71ce3239",
   "metadata": {},
   "source": [
    "## Метрики оценки качества"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c66d00b-b2c4-439d-87a1-27bfc6200cb5",
   "metadata": {},
   "source": [
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Расчет точности (Accuracy)\n",
    "    \n",
    "    Parameters:\n",
    "    y_true - истинные метки классов\n",
    "    y_pred - предсказанные метки классов\n",
    "    \n",
    "    Returns:\n",
    "    accuracy - значение точности\n",
    "    \"\"\"\n",
    "    return np.mean(y_true == y_pred)\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Расчет точности предсказания (Precision)\n",
    "    \n",
    "    Parameters:\n",
    "    y_true - истинные метки классов\n",
    "    y_pred - предсказанные метки классов\n",
    "    \n",
    "    Returns:\n",
    "    precision - значение точности предсказания\n",
    "    \"\"\"\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fp = np.sum((y_true == 0) & (y_pred == 1))\n",
    "    return tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Расчет полноты (Recall)\n",
    "    \n",
    "    Parameters:\n",
    "    y_true - истинные метки классов\n",
    "    y_pred - предсказанные метки классов\n",
    "    \n",
    "    Returns:\n",
    "    recall - значение полноты\n",
    "    \"\"\"\n",
    "    tp = np.sum((y_true == 1) & (y_pred == 1))\n",
    "    fn = np.sum((y_true == 1) & (y_pred == 0))\n",
    "    return tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "\n",
    "# Предсказания и оценка\n",
    "y_pred = tree.predict(X_test)\n",
    "y_proba = tree.predict_proba(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(\"Метрики классификации:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "\n",
    "# Матрица ошибок\n",
    "tp = np.sum((y_test == 1) & (y_pred == 1))\n",
    "fp = np.sum((y_test == 0) & (y_pred == 1))\n",
    "fn = np.sum((y_test == 1) & (y_pred == 0))\n",
    "tn = np.sum((y_test == 0) & (y_pred == 0))\n",
    "\n",
    "print(f\"\\nМатрица ошибок:\")\n",
    "print(f\"TP: {tp}, FP: {fp}\")\n",
    "print(f\"FN: {fn}, TN: {tn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf801d56-ee6e-40ef-8dd6-598900db4e3e",
   "metadata": {},
   "source": [
    "## Визуализация результатов"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
